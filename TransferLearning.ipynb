{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1h-V_eYgwh_"
      },
      "source": [
        "##**Transfer Learning VS Training from Scratch**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWcNxfzJhQu7"
      },
      "source": [
        "## Load Library and Preprocessing step\n",
        "I am using CIFAR-10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy5GKYsmyZGC"
      },
      "source": [
        "#Load libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import datasets, models, layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Flatten, BatchNormalization, Dense, Dropout,Conv2D\n",
        "from tensorflow.image import resize\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJbdRnzfgj1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35e794a-afbb-4938-d2f3-02ac03f99542"
      },
      "source": [
        "#Load and preprocess\n",
        "(x_train, y_train), (x_test, y_test)=datasets.cifar10.load_data()\n",
        "#x_train, x_test = x_train /255.0, x_test /255.0\n",
        "x_train =tf.keras.applications.resnet50.preprocess_input(x_train)\n",
        "x_test = tf.keras.applications.resnet50.preprocess_input(x_test)\n",
        "y_train= tf.keras.utils.to_categorical(y_train,10)\n",
        "y_test= tf.keras.utils.to_categorical(y_test,10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0_4doKUVTon"
      },
      "source": [
        "# Parameters\n",
        "sample_number = x_train.shape[0]\n",
        "img_w =x_train.shape[1]\n",
        "img_h = x_train.shape[2]\n",
        "img_channel = x_train.shape[3]\n",
        "resnet_input_dim = (224,224)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zgYbcklhr0T"
      },
      "source": [
        "## Pretrained model (ResNet50)\n",
        "Setup ResNet50 and freez 143 first layer(All layers except last block)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CItsdU11guJ2"
      },
      "source": [
        "# Create pretrained model  - include_top = False >> No Fully connected layer\n",
        "pretrained_model = ResNet50(include_top=False,\n",
        "                            weights='imagenet')\n",
        "freeze_number = 143\n",
        "for layer in pretrained_model.layers[:freeze_number]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfsUIDutilMT"
      },
      "source": [
        "##Create customized model(ResNet50(Base) + Customized layers (Head))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVB7quT4ilxw"
      },
      "source": [
        "customized_model = Sequential()\n",
        "customized_model.add(tf.keras.layers.Lambda(lambda image:resize(image, resnet_input_dim)))\n",
        "customized_model.add(pretrained_model)\n",
        "customized_model.add(Conv2D(128, (3,3), strides=(1, 1),activation='relu'))\n",
        "customized_model.add(Flatten())\n",
        "customized_model.add(BatchNormalization())\n",
        "customized_model.add(Dense(256, activation='relu'))\n",
        "customized_model.add(Dropout(0.5))\n",
        "customized_model.add(BatchNormalization())\n",
        "customized_model.add(Dense(128, activation='relu'))\n",
        "customized_model.add(Dropout(0.5))\n",
        "customized_model.add(BatchNormalization())\n",
        "customized_model.add(Dense(64, activation='relu'))\n",
        "customized_model.add(Dropout(0.5))\n",
        "customized_model.add(BatchNormalization())\n",
        "customized_model.add(Dense(10, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53Z7eVjRi6QP"
      },
      "source": [
        "##Compileing and Fitting Step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HLwxicBi-cg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac6e8e83-4851-416c-cde2-7b949f308bb6"
      },
      "source": [
        "customized_model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer= 'adam',\n",
        "                  metrics=['accuracy'])\n",
        "customized_callbacks = [EarlyStopping(monitor='accuracy',patience=3,mode='max', verbose=1),\n",
        "                        ModelCheckpoint('/data/',monitor='val_accuracy', save_best_only=True, mode='max',verbose=0)]\n",
        "history = customized_model.fit(x_train,\n",
        "                               y_train,\n",
        "                               batch_size=32,\n",
        "                               epochs=5,\n",
        "                               verbose=1,\n",
        "                               validation_data=(x_test, y_test),\n",
        "                               callbacks=[customized_callbacks])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 252s 159ms/step - loss: 0.5124 - accuracy: 0.8622 - val_loss: 0.2557 - val_accuracy: 0.9191\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 248s 158ms/step - loss: 0.3564 - accuracy: 0.9034 - val_loss: 0.2369 - val_accuracy: 0.9258\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 245s 157ms/step - loss: 0.2597 - accuracy: 0.9325 - val_loss: 0.2645 - val_accuracy: 0.9198\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 247s 158ms/step - loss: 0.2066 - accuracy: 0.9472 - val_loss: 0.2418 - val_accuracy: 0.9265\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 245s 157ms/step - loss: 0.1673 - accuracy: 0.9558 - val_loss: 0.2426 - val_accuracy: 0.9356\n",
            "INFO:tensorflow:Assets written to: /data/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2zsiQTUjBVb"
      },
      "source": [
        "##Plotting Accuracy and Calculating Average of 3 runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLytBpk5PUZd",
        "outputId": "2b609471-4db8-4128-a8f4-55d5412950d4"
      },
      "source": [
        "customized_model.save('customized.model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: customized.model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "na_lhquyo_6n",
        "outputId": "5ca56203-7000-46fe-f8f5-b422ac172d6c"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='Trainging Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'Testing Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "#test_loss, test_acc = customized_model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "sum_train_acc = 0\n",
        "sum_test_acc = 0\n",
        "epoch_num = 3\n",
        "for epoch in range(epoch_num):\n",
        "  sum_train_acc += history.history['accuracy'][epoch]\n",
        "  sum_test_acc += history.history['val_accuracy'][epoch]\n",
        "\n",
        "avg_train_acc = (sum_train_acc / epoch_num)\n",
        "avg_test_acc = (sum_train_acc / epoch_num)\n",
        "\n",
        "print('Training Accuracy Average for Pretrained DCNN',avg_train_acc)\n",
        "print('Testing Accuracy Average for Pretrained DCNN',avg_test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy Average for Pretrained DCNN 0.9008200168609619\n",
            "Testing Accuracy Average for Pretrained DCNN 0.9008200168609619\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EFP7uWIqMsN"
      },
      "source": [
        "##Train DCNN From Scratch\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9eQnZ7DB3xU"
      },
      "source": [
        "res_model = ResNet50(include_top=False,\n",
        "                     weights=None,\n",
        "                     pooling='avg',\n",
        "                     input_shape =(img_w,img_h,img_channel))\n",
        "random_w_model = Sequential()\n",
        "random_w_model.add(res_model)\n",
        "random_w_model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S51OPpjiqqZ-",
        "outputId": "45876cde-0376-4078-d0c3-4d025b5f9c5a"
      },
      "source": [
        "random_w_model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer= 'adam',\n",
        "                  metrics=['accuracy'])\n",
        "customized_callbacks_scratch = [EarlyStopping(monitor='accuracy',patience=3,mode='max', verbose=1),\n",
        "                        ModelCheckpoint('/data/',monitor='val_accuracy', save_best_only=True, mode='max',verbose=0)]\n",
        "history_r = random_w_model.fit(x_train,\n",
        "                               y_train,\n",
        "                               batch_size=32,\n",
        "                               epochs=100,\n",
        "                               verbose=1,\n",
        "                               validation_data=(x_test, y_test),\n",
        "                               callbacks=[customized_callbacks_scratch])\n",
        "random_w_model.save('random_w_model.model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 72s 43ms/step - loss: 2.3606 - accuracy: 0.2529 - val_loss: 2.1822 - val_accuracy: 0.2400\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 2.2930 - accuracy: 0.2483 - val_loss: 1.9881 - val_accuracy: 0.2870\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 2.1003 - accuracy: 0.3228 - val_loss: 4.5527 - val_accuracy: 0.2351\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 65s 42ms/step - loss: 2.1364 - accuracy: 0.2846 - val_loss: 2.7746 - val_accuracy: 0.2978\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 1.9463 - accuracy: 0.3477 - val_loss: 2.9440 - val_accuracy: 0.3031\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 65s 42ms/step - loss: 1.9580 - accuracy: 0.3433 - val_loss: 2.2559 - val_accuracy: 0.4235\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 1.7036 - accuracy: 0.4151 - val_loss: 1.6984 - val_accuracy: 0.4582\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 1.6162 - accuracy: 0.4422 - val_loss: 1.5083 - val_accuracy: 0.4547\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 65s 42ms/step - loss: 1.5584 - accuracy: 0.4559 - val_loss: 1.5069 - val_accuracy: 0.4767\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 1.4378 - accuracy: 0.4883 - val_loss: 1.7391 - val_accuracy: 0.4499\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 1.4527 - accuracy: 0.4831 - val_loss: 1.4112 - val_accuracy: 0.5041\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 65s 42ms/step - loss: 1.2497 - accuracy: 0.5588 - val_loss: 1.1363 - val_accuracy: 0.5950\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 1.1164 - accuracy: 0.6094 - val_loss: 1.0902 - val_accuracy: 0.6149\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 0.9959 - accuracy: 0.6517 - val_loss: 1.0079 - val_accuracy: 0.6434\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 0.8902 - accuracy: 0.6856 - val_loss: 0.9773 - val_accuracy: 0.6580\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 0.7960 - accuracy: 0.7202 - val_loss: 0.8486 - val_accuracy: 0.7033\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.7140 - accuracy: 0.7491 - val_loss: 0.8146 - val_accuracy: 0.7143\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.6289 - accuracy: 0.7813 - val_loss: 0.8336 - val_accuracy: 0.7189\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.5624 - accuracy: 0.8053 - val_loss: 1.3441 - val_accuracy: 0.6140\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.5118 - accuracy: 0.8231 - val_loss: 0.8071 - val_accuracy: 0.7353\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 68s 44ms/step - loss: 0.4514 - accuracy: 0.8425 - val_loss: 0.8339 - val_accuracy: 0.7312\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.3722 - accuracy: 0.8706 - val_loss: 0.9127 - val_accuracy: 0.7162\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.3358 - accuracy: 0.8835 - val_loss: 0.8251 - val_accuracy: 0.7435\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 68s 43ms/step - loss: 0.3238 - accuracy: 0.8894 - val_loss: 1.2032 - val_accuracy: 0.6869\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2684 - accuracy: 0.9066 - val_loss: 1.0002 - val_accuracy: 0.7281\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2306 - accuracy: 0.9196 - val_loss: 0.9285 - val_accuracy: 0.7357\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2068 - accuracy: 0.9304 - val_loss: 0.9793 - val_accuracy: 0.7353\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1704 - accuracy: 0.9424 - val_loss: 1.0213 - val_accuracy: 0.7301\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2356 - accuracy: 0.9200 - val_loss: 1.0971 - val_accuracy: 0.7252\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1478 - accuracy: 0.9507 - val_loss: 1.1283 - val_accuracy: 0.7351\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1196 - accuracy: 0.9567 - val_loss: 1.1152 - val_accuracy: 0.7418\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1517 - accuracy: 0.9482 - val_loss: 1.1026 - val_accuracy: 0.7435\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1079 - accuracy: 0.9627 - val_loss: 1.6958 - val_accuracy: 0.6435\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.2173 - accuracy: 0.9276 - val_loss: 1.3225 - val_accuracy: 0.7295\n",
            "Epoch 00034: early stopping\n",
            "INFO:tensorflow:Assets written to: random_w_model.model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkQKS1jS6U0a",
        "outputId": "ba5c32f4-32c7-42e9-e9be-3d1c03bf3243"
      },
      "source": [
        "\n",
        "sum_train_acc_rw = 0\n",
        "sum_test_acc_rw = 0\n",
        "\n",
        "epoch_num = 34\n",
        "for epoch in range(epoch_num):\n",
        "  sum_train_acc_rw += history_r.history['accuracy'][epoch]\n",
        "  sum_test_acc_rw += history_r.history['val_accuracy'][epoch]\n",
        "\n",
        "avg_train_acc = (sum_train_acc_rw / epoch_num)\n",
        "avg_test_acc = (sum_train_acc_rw / epoch_num)\n",
        "print('Training Accuracy Average for Pretrained DCNN',avg_train_acc)\n",
        "print('Testing Accuracy Average for Pretrained DCNN',avg_test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy Average for Pretrained DCNN 0.6866182347430902\n",
            "Testing Accuracy Average for Pretrained DCNN 0.6866182347430902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5Oz0kwhleJa"
      },
      "source": [
        "##Train DCNN From Scratch - CUSTOMIZED\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xMEseDSlX8d"
      },
      "source": [
        "r_model = ResNet50(include_top=False,\n",
        "                     weights=None,\n",
        "                     pooling='avg',\n",
        "                     )\n",
        "my_model = Sequential()\n",
        "\n",
        "my_model.add(tf.keras.layers.Lambda(lambda image:resize(image, resnet_input_dim)))\n",
        "my_model.add(r_model)\n",
        "\n",
        "my_model.add(Flatten())\n",
        "my_model.add(BatchNormalization())\n",
        "my_model.add(Dense(256, activation='relu'))\n",
        "my_model.add(Dropout(0.5))\n",
        "my_model.add(BatchNormalization())\n",
        "my_model.add(Dense(128, activation='relu'))\n",
        "my_model.add(Dropout(0.5))\n",
        "my_model.add(BatchNormalization())\n",
        "my_model.add(Dense(64, activation='relu'))\n",
        "my_model.add(Dropout(0.5))\n",
        "my_model.add(BatchNormalization())\n",
        "my_model.add(Dense(10, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxYPa01pm-WV",
        "outputId": "205718d9-3572-4e1e-ab15-d2e762d7277e"
      },
      "source": [
        "my_model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer= 'adam',\n",
        "                  metrics=['accuracy'])\n",
        "my_callbacks = [EarlyStopping(monitor='accuracy',patience=3,mode='max', verbose=1),\n",
        "                        ModelCheckpoint('/data/',monitor='val_accuracy', save_best_only=True, mode='max',verbose=0)]\n",
        "my_history = my_model.fit(x_train,\n",
        "                               y_train,\n",
        "                               batch_size=32,\n",
        "                               epochs=30,\n",
        "                               verbose=1,\n",
        "                               validation_data=(x_test, y_test),\n",
        "                               callbacks=[my_callbacks])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 520s 329ms/step - loss: 2.3454 - accuracy: 0.1634 - val_loss: 3.2141 - val_accuracy: 0.1618\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 512s 328ms/step - loss: 1.8696 - accuracy: 0.2796 - val_loss: 1.6478 - val_accuracy: 0.3601\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 513s 328ms/step - loss: 1.6697 - accuracy: 0.3620 - val_loss: 1.4600 - val_accuracy: 0.4414\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 514s 329ms/step - loss: 1.4681 - accuracy: 0.4596 - val_loss: 1.3259 - val_accuracy: 0.5053\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 513s 328ms/step - loss: 1.2982 - accuracy: 0.5380 - val_loss: 1.1595 - val_accuracy: 0.5680\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 513s 328ms/step - loss: 1.1475 - accuracy: 0.6056 - val_loss: 1.0345 - val_accuracy: 0.6271\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 515s 329ms/step - loss: 1.0416 - accuracy: 0.6458 - val_loss: 0.8294 - val_accuracy: 0.7081\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 514s 329ms/step - loss: 0.9611 - accuracy: 0.6777 - val_loss: 0.8551 - val_accuracy: 0.7008\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 514s 329ms/step - loss: 0.8928 - accuracy: 0.7063 - val_loss: 0.8208 - val_accuracy: 0.7118\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 514s 329ms/step - loss: 0.8915 - accuracy: 0.7129 - val_loss: 0.7143 - val_accuracy: 0.7547\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 514s 329ms/step - loss: 0.7864 - accuracy: 0.7469 - val_loss: 0.8319 - val_accuracy: 0.7103\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 513s 329ms/step - loss: 0.7481 - accuracy: 0.7584 - val_loss: 0.6721 - val_accuracy: 0.7728\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 515s 329ms/step - loss: 0.7046 - accuracy: 0.7805 - val_loss: 0.6432 - val_accuracy: 0.7832\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 514s 329ms/step - loss: 0.6840 - accuracy: 0.7832 - val_loss: 0.5926 - val_accuracy: 0.7972\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 513s 328ms/step - loss: 0.6581 - accuracy: 0.7944 - val_loss: 0.6055 - val_accuracy: 0.7992\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 514s 329ms/step - loss: 0.5926 - accuracy: 0.8149 - val_loss: 0.5912 - val_accuracy: 0.7996\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 514s 329ms/step - loss: 0.5548 - accuracy: 0.8283 - val_loss: 0.7118 - val_accuracy: 0.7673\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 513s 328ms/step - loss: 0.5200 - accuracy: 0.8387 - val_loss: 0.6015 - val_accuracy: 0.8024\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 514s 329ms/step - loss: 0.4741 - accuracy: 0.8521 - val_loss: 0.5505 - val_accuracy: 0.8219\n",
            "INFO:tensorflow:Assets written to: /data/assets\n",
            "Epoch 20/30\n",
            " 550/1563 [=========>....................] - ETA: 5:15 - loss: 0.4629 - accuracy: 0.8586"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEcW4lgR8zN-"
      },
      "source": [
        "**Question** Compare the performance gab and training time between the above two conditions. Please explain why you obtained such results, and give a brief discussion about it. Based on the paper (Rethinking ImageNet Pre-training, ICCV,2019), the ImageNet pretrained model does not improve accuracy unless the target dataset is too small. Did your experimental result support the conclusion?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEzJbj9w-uZp"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIjyB5fV-Mk_"
      },
      "source": [
        "**Question**\n",
        "compare the performance gab and training time between your results (training from scratch) and your results in the Home Assignment 2 Part I. Explain why you obtained such results, and give a brief discussion of why the results are different. (hint: Equation (21) in the slides in Week3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53tOJNG2-UY9"
      },
      "source": [
        ""
      ]
    }
  ]
}